{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHI7gfZhya5W",
        "outputId": "6080502f-d9c7-4add-f584-32c411a9c87f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import DistilBertTokenizerFast, DistilBertModel\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "0_ln3noww3tD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = DistilBertTokenizerFast.from_pretrained(\"/content/drive/MyDrive/Colab Notebooks/Final Project AI/tokenizer/G15_tokenizer\")"
      ],
      "metadata": {
        "id": "qwq_Bo87ySNd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir('/content/drive/MyDrive/Colab Notebooks/Final Project AI/tokenizer/G15_tokenizer'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SE-kWlz45u0",
        "outputId": "7109ecce-86e0-4b01-f45d-0062af3e13cd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tokenizer.json', 'vocab.txt', 'tokenizer_config.json', 'special_tokens_map.json']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model architecture\n",
        "class CustomDistilBertModel(nn.Module):\n",
        "    def __init__(self, base_model, num_labels, freeze_base=True, use_custom_head=True):\n",
        "        super(CustomDistilBertModel, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        if freeze_base:\n",
        "            for param in self.base_model.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        if use_custom_head:\n",
        "            self.dropout = nn.Dropout(p=0.3)\n",
        "            self.classifier = nn.Linear(768, num_labels)  # Assuming 768 is the base model output size\n",
        "        else:\n",
        "            self.classifier = nn.Identity()\n",
        "\n",
        "        self.use_custom_head = use_custom_head\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_state = outputs.last_hidden_state[:, 0, :]\n",
        "        if self.use_custom_head:\n",
        "            hidden_state = self.dropout(hidden_state)\n",
        "        logits = self.classifier(hidden_state)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "f4NnuMc2ydgn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "base_model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
        "model = CustomDistilBertModel(base_model, num_labels=5)"
      ],
      "metadata": {
        "id": "J6jwM-yVxCs3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d28466d1-27ef-4f89-83d8-e981a46254db"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the saved state dict\n",
        "\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/Final Project AI/model.pth', map_location=torch.device('cpu')))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCGeuFjUyzlb",
        "outputId": "09c5622a-5b87-4872-cca7-2d8ec9050830"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomDistilBertModel(\n",
              "  (base_model): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(comment):\n",
        "    # tokenize my input\n",
        "    inputs = tokenizer(comment, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "    input_ids = inputs[\"input_ids\"]\n",
        "    attention_mask = inputs[\"attention_mask\"]\n",
        "\n",
        "    # make prediction\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        probs = torch.softmax(outputs, dim=1)\n",
        "\n",
        "    return preds, probs"
      ],
      "metadata": {
        "id": "F7KGLBryz9l8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comment = \"I loved this product. It was amazing!\""
      ],
      "metadata": {
        "id": "04PzNaBm0G3o"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction, probs = predict(comment)"
      ],
      "metadata": {
        "id": "JwIv2FSZ0d8x"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "058xZnMc1eGP",
        "outputId": "488c2ef9-36cd-4e00-b5a8-942386b3b78c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcDN3kcC1PY5",
        "outputId": "986e7f27-58be-4e98-c6b1-a5b6eb0e95b5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0105, 0.0063, 0.0083, 0.0759, 0.8990]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Comment: {comment}\")\n",
        "print(f\"Predicted class: {prediction.item() + 1}\")\n",
        "print(f\"Probability: {probs[0][prediction].item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6I4RDGSC0hGs",
        "outputId": "ae5d6274-4526-4ebb-a0e6-a0cd80c034e0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comment: I loved this product. It was amazing!\n",
            "Predicted class: 5\n",
            "Probability: 0.8990\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "print(transformers.__version__)\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnfgTj1300oA",
        "outputId": "dadd332c-a5e2-45ea-a4bc-33da3ed312ff"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.42.4\n",
            "2.3.1+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Evaluation of Model"
      ],
      "metadata": {
        "id": "T5ic1PoaDfgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZPypNKuDp1Y",
        "outputId": "47bf4bf9-87d0-46c3-f42a-ea5988bcaba7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "dataset = load_dataset('gyoungjr/amazon-electronics-reviews')\n",
        "\n",
        "test_data = pd.DataFrame(dataset[\"test\"])"
      ],
      "metadata": {
        "id": "TX7WLlPD6pXI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean the test data\n",
        "import re\n",
        "\n",
        "def remove_special(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = ' '.join(text.split())\n",
        "    return text\n",
        "\n",
        "def clean_data(data):\n",
        "    data[\"labels\"] = data[\"labels\"].astype(int)\n",
        "    data[\"text\"] = data[\"text\"].astype(str)\n",
        "    data.drop_duplicates(keep='last')\n",
        "    data[\"text\"].apply(remove_special)\n",
        "    return data\n",
        "\n",
        "test_data = clean_data(test_data)"
      ],
      "metadata": {
        "id": "5uYVxZ62Dtky"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, texts, labels, max_length=512):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens = tokenizer(self.texts[idx], return_tensors=\"pt\", truncation=True, padding='max_length', max_length=self.max_length)\n",
        "        input_ids = tokens['input_ids'].squeeze(0)\n",
        "        attention_mask = tokens['attention_mask'].squeeze(0)\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return input_ids, attention_mask, label"
      ],
      "metadata": {
        "id": "DfDM1YQcD9ES"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create custom dataset\n",
        "test_dataset = CustomDataset(test_data[\"text\"].tolist(), test_data[\"labels\"].tolist())"
      ],
      "metadata": {
        "id": "mKLyOjvRD1rF"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "lBudGySWEdyZ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a80aSvvSKL9F",
        "outputId": "c68e4305-63fa-4e36-904f-7e0275ec9760"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomDistilBertModel(\n",
              "  (base_model): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n",
        "\n",
        "with torch.no_grad():\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    for batch in test_loader:\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        all_preds.extend(preds.tolist())\n",
        "        all_labels.extend(labels.tolist())\n",
        "\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "precision = precision_score(all_labels, all_preds, average='weighted')\n",
        "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9ipWbydKPY_",
        "outputId": "8a1a5b6a-c099-4141-e8ae-f6710379a509"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4939\n",
            "Precision: 0.4804\n",
            "Confusion Matrix:\n",
            "[[1362  336  133   74   45]\n",
            " [ 594  549  320  141   51]\n",
            " [ 323  396  671  463  186]\n",
            " [ 105  110  296  778  735]\n",
            " [  73   31   72  405 1411]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall we can say that the model is about 50% accurate with it's predictions."
      ],
      "metadata": {
        "id": "GyplCas_zUlM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KhBY2RR7lXSY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}